{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 췅 Modelos avanzados de miner칤a de datos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2022-2 췅 M치ster universitario en Ciencia de datos (<i>Data science</i>)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Inform치tica, Multimedia y Telecomunicaci칩n</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEC 3: M칠todos supervisados\n",
    "\n",
    "En esta pr치ctica veremos diferentes m칠todos supervisados y trataremos de optimizar diferentes m칠tricas. Veremos como los diferentes modelos clasifican los puntos y con cuales obtenemos mayor precisi칩n. Despu칠s aplicaremos todo lo que hemos aprendido hasta ahora a un dataset nuevo simulando un caso pr치ctico real.\n",
    "\n",
    "1. [Exploraci칩n de algoritmos supervisados](#eje1) \\\n",
    "    1.0. Carga de datos \\\n",
    "    1.1. Naive-Bayes\\\n",
    "    1.2. An치lisis Discriminante Lineal (LDA) y An치lisis Discriminante Cuadrt치tico (QDA)\\\n",
    "    1.3. K vecinos m치s pr칩ximos (KNN)\\\n",
    "    1.4. M치quinas de soporte vectorial (SVM)\\\n",
    "    1.5. 츼rboles de decisi칩n\n",
    "2. [Implementaci칩n del caso pr치ctico](#ej2)\\\n",
    "    2.0. Carga de datos\\\n",
    "    2.1. An치lisis descriptivo\\\n",
    "    2.2. Entrenamiento, validaci칩n y prueba de una red neuronal con los datos originales\\\n",
    "    2.3. Submuestreo\\\n",
    "    2.4. Sobremuestreo\\\n",
    "    2.5. Generaci칩n de datos sint칠ticos\\\n",
    "    2.6. Sintonizando los modelos (BONUS)\n",
    "\n",
    "<u>Consideraciones generales</u>: \n",
    "\n",
    "- La soluci칩n planteada no puede utilizar m칠todos, funciones o par치metros declarados **_deprecated_** en futuras versiones, a excepci칩n de la carga de datos c칩mo se indica posteriormente.\n",
    "- Esta PEC debe realizarse de forma **estrictamente individual**. Cualquier indicio de copia ser치 penalizado con un suspenso (D) para todas las partes implicadas y la posible evaluaci칩n negativa de la asignatura de forma 칤ntegra.\n",
    "- Es necesario que el estudiante indique **todas las fuentes** que ha utilizado para la realizaci칩n de la PEC. De no ser as칤, se considerar치 que el estudiante ha cometido plagio, siendo penalizado con un suspenso (D) y la posible evaluaci칩n negativa de la asignatura de forma 칤ntegra.\n",
    "\n",
    "<u>Formato de la entrega</u>:\n",
    "\n",
    "- Algunos ejercicios pueden suponer varios minutos de ejecuci칩n, por lo que la entrega debe hacerse en **formato notebook** y en **formato html**, donde se vea el c칩digo, los resultados y comentarios de cada ejercicio. Se puede exportar el notebook a HTML desde el men칰 File $\\to$ Download as $\\to$ HTML.\n",
    "- Existe un tipo de celda especial para albergar texto. Este tipo de celda os ser치 muy 칰til para responder a las diferentes preguntas te칩ricas planteadas a lo largo de la actividad. Para cambiar el tipo de celda a este tipo, en el men칰: Cell $\\to$ Cell Type $\\to$ Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Nombre y apellidos:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ej1'></a>\n",
    "# 1. Exploraci칩n de algoritmos supervisados\n",
    "\n",
    "## 1.0. Carga de datos\n",
    "\n",
    "El conjunto de datos Spiral es un conjunto de datos sint칠ticos que se utiliza com칰nmente en el aprendizaje autom치tico y la miner칤a de datos como un problema de clasificaci칩n no lineal. El conjunto de datos consta de dos espirales entrelazadas que se asemejan a las espirales de Arqu칤medes. Cada espiral se compone de un conjunto de puntos distribuidos uniformemente en el plano, y los puntos de cada espiral est치n etiquetados con una clase diferente.\n",
    "\n",
    "El objetivo es utilizar un algoritmo de clasificaci칩n para predecir la clase de un punto desconocido en funci칩n de sus coordenadas (x, y). Debido a la naturaleza entrelazada de las espirales, este problema de clasificaci칩n es no lineal y, por lo tanto, es un desaf칤o interesante para los algoritmos de aprendizaje autom치tico.\n",
    "\n",
    "El siguiente c칩digo cargar치 2000 puntos en la variable `X` y la correspondientes etiqueta o grupo (en forma num칠rica) en la variable `y`. Podemos comprobar que la carga ha sido correcta obteniendo las dimensiones de estas dos variables y el gr치fico de los puntos (con colores diferentes para cada grupo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('spiral.pickle')\n",
    "\n",
    "# Convertir las dos primeras columnas en un array de numpy\n",
    "X = data[['X1', 'X2']].values\n",
    "\n",
    "# Convertir la 칰ltima columna en un array de numpy\n",
    "y = data['y'].values\n",
    "\n",
    "print('Dimensiones de X', X.shape)\n",
    "print('Dimensiones de y', y.shape)\n",
    "\n",
    "# Hacer la representaci칩n gr치fica\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.viridis, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de los ejercicios aprenderemos a ver gr치ficamente las fronteras de decisi칩n que nos devuelven los diferentes modelos. Para ello utilizaremos la funci칩n definida a continuaci칩n, que sigue los siguientes pasos:\n",
    "\n",
    "   - Crear una [meshgrid](https://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html) con los valores m칤nimo y m치ximo de 'x' e 'y'.\n",
    "   - Predecir el clasificador con los valores de la _meshgrid_.\n",
    "   - Hacer un _reshape_ de los datos para tener el formato correspondiente.\n",
    "  \n",
    "Una vez hecho esto, ya podemos hacer el gr치fico de las fronteras de decisi칩n y a침adir los puntos reales. As칤 veremos las 치reas que el modelo considera que son de una clase y las que considera que son de otra. Al poner encima los puntos veremos si los clasifica correctamente en el 치rea que les corresponde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, Y, cmap='Paired'):\n",
    "    if not isinstance(X, np.ndarray):  # Si X no es un array de numpy, lo convierte\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:,0].min() - 10*h, X[:,0].max() + 10*h\n",
    "    y_min, y_max = X[:,1].min() - 10*h, X[:,1].max() + 10*h\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.25)\n",
    "    plt.contour(xx, yy, Z, colors='k', linewidths=0.7)\n",
    "    plt.scatter(X[:,0], X[:,1], c=Y, cmap=cmap, edgecolors='k', label=Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci칩n:</strong> \n",
    "\n",
    "Dividid el _dataset_ en dos subconjuntos, __*train*__ (80% de los datos) y __*test*__ (20% de los datos). Nombrad los conjuntos como: X_train, X_test, y_train, y_test. Utilizad la opci칩n `random_state = 24`.\n",
    "    \n",
    "Pod칠is utilizar la implementaci칩n `train_test_split` de `sklearn`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Gaussian Na칦ve Bayes\n",
    "\n",
    "El objetivo de este primer ejercicio es entender el funcionamiento del algoritmo Na칦ve-Bayes, un algoritmo peculiar ya que se basa en el teorema de Bayes para calcular la probabilidad de que una observaci칩n pertenezca a cada una de las clases. El modelo asume que las caracter칤sticas de entrada son independientes entre s칤, lo que permite simplificar el c치lculo de las probabilidades condicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong> \n",
    "\n",
    "- Con el dataset de _train_, entrenad un modelo de Na칦ve-Bayes. Pod칠is utilizar el clasificador `GaussianNB` de `sklearn`.\n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "    \n",
    "Pod칠is utilizar la funci칩n `plot_decision_boundary` creada previamente, y las funciones `accuracy_score` y `confusion_matrix` del paquet `metrics` de `sklearn`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - 쮺칩mo son las fronteras de decisi칩n? 쯊iene sentido que tengan esta forma con el algoritmo utilizado?\n",
    "   - 쮺칩mo son las predicciones obtenidas sobre el conjunto de test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 An치lisis Discriminante Lineal (LDA) y An치lisis Discriminante Cuadrt치tico (QDA)\n",
    "\n",
    "Ahora analizaremos dos algoritmos que se basan en la transformaci칩n lineal de las caracter칤sticas de entrada para maximizar la separaci칩n entre las clases. Estos modelos suponen que las caracter칤sticas tienen una distribuci칩n gaussiana y as칤 poder calcular las probabilidades condicionales de cada clase y asignar la clase con la mayor probabilidad como la clase predicha para una observaci칩n dada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong> \n",
    "\n",
    "- Con el dataset de _train_, entrenad un modelo de An치lisis Discriminate Lineal (LDA). Pod칠is utilizar el clasificador `LinearDiscriminantAnalysis` de `sklearn`.\n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - 쮺칩mo son las fronteras de decisi칩n? 쯊iene sentido que tengan esta forma con el algoritmo utilizado?\n",
    "   - 쮺칩mo son las predicciones obtenidas sobre el conjunto de test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong> \n",
    "\n",
    "- Con el dataset de _train_, entrenad un modelo de An치lisis Discriminate Cuadr치tico (QDA). Pod칠is utilizar el clasificador `QuadraticDiscriminantAnalysis` de `sklearn`.\n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong> \n",
    "\n",
    "   - 쮺칩mo son las fronteras de decisi칩n? 쯊iene sentido que tengan esta forma con el algoritmo utilizado?\n",
    "   - 쮺칩mo son las predicciones obtenidas sobre el conjunto de test?\n",
    "   - 쮼n que se diferencian el algoritmo LDA del QDA?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. K- vecinos m치s pr칩ximos KNN\n",
    "\n",
    "En este punto entenderemos el funcionamiento del algoritmo KNN (que se basa en la proximidad de los puntos de datos en un espacio de caracter칤sticas), intuir sus principales ventajas o desventajas y entender la influencia de los par치metros de los que est치 compuesto.\n",
    "\n",
    "K-Nearest-Neighbor es un algoritmo basado en instancia de tipo supervisado. \n",
    "\n",
    "Vamos a ver qu칠 significa esto:\n",
    "\n",
    "  - Supervisado: tenemos etiquetado nuestro conjunto de datos de entrenamiento, con la clase o resultado esperado.\n",
    "  - Basado en instancia (_Lazy Learning_): Esto significa que nuestro algoritmo no aprende expl칤citamente un modelo (como por ejemplo en Regresi칩n Log칤stica o 치rboles de decisi칩n), sino que memoriza las instancias de entrenamiento que son utilizadas como \"conocimiento\" para la fase de predicci칩n.\n",
    "\n",
    "쮺칩mo funciona KNN?\n",
    "\n",
    "  - Calculamos la distancia entre el 칤tem a clasificar y los dem치s 칤tems del dataset de entrenamiento.\n",
    "  - Seleccionamos los \"k\" elementos m치s cercanos, es decir, con menor distancia, seg칰n la distancia que utilizamos (eucl칤dea, coseno, manhattan, etc).\n",
    "  - Por 칰ltimo realizamos una \"votaci칩n de mayor칤a\" entre los k puntos: los de la clase que \"dominan\" decidir치n su clasificaci칩n final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Con el dataset de _train_, entrenad un clasificador KNN con hiperpar치metro `n_neighbors=2`. Pod칠is utilizar el clasificador `KNeighborsClassifier` de `sklearn`.\n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "\n",
    "\n",
    "Si al entrenar el clasificador sale un warning y lo quieres ignorar, ejecuta el siguiente c칩digo antes del entrenamiento:\n",
    "\n",
    "`import warnings`\\\n",
    "`warnings.filterwarnings('ignore', message='^.*will change.*$', category=FutureWarning)`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='^.*will change.*$', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el modelo entrenado, hemos fijado el par치metro `n_neighbors` de forma arbitraria. Pero podr칤a ser que con otro valor obtuvi칠ramos una mejor predicci칩n.\n",
    "\n",
    "Para conocer el valor 칩ptimo de los par치metros de un modelo (_hyperparameter tunning_) se suele utilizar una b칰squeda de rejilla (_grid search_). Es decir, entrenar un modelo para cada combinaci칩n de hiperpar치metros posible y evaluarlo utilizando validaci칩n cruzada (_cross validation_) con 5 particiones estratificadas. Posteriormente, se elige la combinaci칩n de hiperpar맔etres que mejores resultados haya obtenido.\n",
    "\n",
    "En este caso s칩lo queremos optimizar un hiperpar치metro:\n",
    "\n",
    "   - 洧녲: el n칰mero de vecinos que se consideran para clasificar un nuevo ejemplo. Probaremos con todos los valores entre 1 y 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci칩n:</strong>\n",
    "\n",
    "C치lculo del valor 칩ptimo del hiperpar치metro _k_ (`n_neighbors`). Utilizad una b칰squeda de rejilla con validaci칩n cruzada para encontrar el valor 칩ptimo de _k_. Por cada valor, calculad su promedio y la desviaci칩n est치ndar. Implementad un _heatmap_ para visualizar la precisi칩n seg칰n los diferentes valores del hiperpar치metro.\n",
    "    \n",
    "Puede utilizar el m칩dulo `GridSearchCV` de `sklearn` el c치lculo del mejor hiperpar치metro, y `heatmap` de `Seaborn`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Con el dataset de _train_, entrenad un clasificador KNN con el mejor hiperpar치metro encontrado. \n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong> \n",
    "\n",
    "   - Comentar los resultados de la b칰squeda del mejor hiperpar치metro.\n",
    "   - 쮺칩mo se visualiza gr치ficamente el cambio del valor `n_neighbors`? 쯊iene sentido esta diferencia entre los dos gr치ficos al cambiar el par치metro?\n",
    "   - 쮺칩mo son las fronteras de decisi칩n? 쯊iene sentido que tengan esta forma con el algoritmo utilizado?\n",
    "   - 쮺칩mo son las predicciones obtenidas sobre el conjunto de test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. M치quinas de soporte vectorial SVM\n",
    "\n",
    "Las Support Vector Machine (SVM) se fundamentan en el _Maximal Margin Classifier_, que a su vez, se basan en el concepto de hiperplano.\n",
    "\n",
    "En un espacio p-dimensional, un hiperplano se define como un subespacio plano y af칤n de dimensiones p-1. El t칠rmino af칤n significa que el subespacio no debe pasar por el origen. En un espacio de dos dimensiones, el hiperplano es un subespacio de 1 dimensi칩n, es decir, una recta. En un espacio tridimensional, un hiperplano es un subespacio de dos dimensiones, un plano convencional. Para dimensiones p>3 no es intuitivo visualizar un hiperplano, pero el concepto de subespacio con p-1 dimensiones se mantiene.\n",
    "\n",
    "La definici칩n de hiperplano para casos perfectamente separables linealmente resulta en un n칰mero infinito de posibles hiperplanos, lo que hace necesario un m칠todo que permita seleccionar uno de ellos como clasificador 칩ptimo.\n",
    "\n",
    "La soluci칩n a este problema consiste en seleccionar como clasificador 칩ptimo al que se conoce como _maximal margin hyperplane_ o hiperplano 칩ptimo de separaci칩n, que se corresponde con el hiperplano que se encuentra m치s alejado de todas las observaciones de entrenamiento. Para obtenerlo, se debe calcular la distancia perpendicular de cada observaci칩n a un determinado hiperplano. La menor de estas distancias (conocida como margen) determina c칩mo de lejos est치 el hiperplano de las observaciones de entrenamiento. El _maximal margin hyperplane_ se define como el hiperplano que consigue un mayor margen, es decir, que la distancia m칤nima entre el hiperplano y las observaciones es lo m치s grande posible. Aunque esta idea suena razonable, no es posible aplicarla, ya que habr칤a infinitos hiperplanos contra los que medir las distancias. En su lugar, se recurre a m칠todos de optimizaci칩n.\n",
    "\n",
    "El proceso de optimizaci칩n tiene la peculiaridad de que s칩lo las observaciones que se encuentran justo al margen o que lo violan influyen sobre el hiperplano. A estas observaciones se les conoce como vectores soporte (_vectors suport_) y son las que definen el clasificador obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los _kernels_ en SVM\n",
    "\n",
    "Hay veces en que no hay manera de encontrar un hiperplano que permita separar dos clases. En estos casos decimos que las clases no son linealmente separables. Para resolver este problema podemos utilizar el truco del n칰cleo .\n",
    "\n",
    "El truco del n칰cleo (_kernel trick_) consiste en utilizar una dimensi칩n nueva en la que podamos encontrar un hiperplano para separar las clases. Se puede ver un un ejemplo en: https://www.youtube.com/watch?v=OdlNM96sHio\n",
    "\n",
    "Al igual que en el algoritmo visto anteriormente (KNN), las SVM tambi칠n dependen de varios hiperpar치metros. \n",
    "\n",
    "En este caso intentaremos optimizar dos hiperpar치metros:\n",
    "\n",
    "  - **C**: es la regularizaci칩n, es decir, el valor de penalizaci칩n de los errores en la clasificaci칩n. Indica el compromiso entre obtener el hiperplano con el margen m치s grande posible y clasificar el m치ximo n칰mero de ejemplos correctamente. Probaremos los valores: 0.01, 0.1, 1, 10, 50, 100 y 200.\n",
    "  \n",
    "  - **Gama**: coeficiente que multiplica la distancia entre dos puntos en el kernel radial. Para decirlo a \"grosso modo\", cuanto m치s peque침o es gama, m치s influencia tienen dos puntos cercanos. Probaremos los valores: 0.001, 0.01, 0.1, 1 y 10.\n",
    "  \n",
    "Al igual que en el caso anterior, para validar el rendimiento del algoritmo con cada combinaci칩n de hiperpar치metros utilizaremos validaci칩n cruzada (_cross-validation_) con 4 particiones estratificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci칩n:</strong> \n",
    "\n",
    "C치lcular del valor 칩ptimo de los hiperpar치metros _C_ y _gama_. Utilizad una b칰squeda de rejilla con validaci칩n cruzada para encontrar los valores 칩ptimos. Para cada combinaci칩n de valores, calcular su promedio y la desviaci칩n est치ndar. Haced un _heatmap_ para visualizar la precisi칩n seg칰n los diferentes valores de los hiperpar치metros.\n",
    "\n",
    "Pod칠is utilizar el m칩dulo `GridSearchCV` de `sklearn` el c치lculo de los mejores hiperpar치metros con el clasificador SVC (de `SVM` de `sklearn`), y `heatmap` de `Seaborn`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Con el dataset de _train_, entrenad un modelo de SVM con la mejor combinaci칩n de par치metros encontrada. \n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - Comentar los resultados de la b칰squeda de los mejores hiperpar치metros.\n",
    "   - 쮺칩mo son las fronteras de decisi칩n? 쯊iene sentido que tengan esta forma con el algoritmo utilizado?\n",
    "   - 쮺칩mo son las predicciones obtenidas sobre el conjunto de test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. 츼rboles de decisi칩n\n",
    "\n",
    "Los 치rboles de decisi칩n son modelos predictivos formados por reglas binarias (si / no) con las que se consigue repartir las observaciones en funci칩n de sus atributos y predecir as칤 el valor de la variable respuesta.\n",
    "\n",
    "Los 치rboles pueden ser **clasificadores** (para clasificar clases, tales como nuestro ejemplo), o bien **regresores** (para predecir variables continuas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construcci칩n de un 치rbol\n",
    "\n",
    "La creaci칩n de las ramificaciones de los 치rboles se logra mediante el algoritmo de *recursive binary splitting*. Este algoritmo consta de tres pasos principales:\n",
    "\n",
    "   - El proceso se inicia en lo alto del 치rbol, donde todas las observaciones pertenecen a la misma regi칩n.\n",
    "   - Se identifican todos los posibles puntos de corte para cada uno de los predictores. Los puntos de corte son cada uno de sus niveles.\n",
    "   - se eval칰an las posibles divisiones de cada predictor de acuerdo a una determinada medida. En el caso de los clasificadores se utilizan: *classification error rate*, Gini, entrop칤a, chi-square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Con el dataset de _train_, entrenad un arbol de desici칩n. Pod칠is utilizar el clasificador `DecisionTreeClassifier` (de `tree` de `sklearn`).\n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_. \n",
    "    \n",
    "- Representad el 치rbol. Pod칠is utilizar el comando `plot.tree` de la biblioteca `tree` de `sklearn`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong> \n",
    "\n",
    "   - Comentad los resultados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evitando el *overfitting*\n",
    "\n",
    "El proceso de construcci칩n de 치rboles descrito tiende a reducir r치pidamente el error de entrenamiento, por lo que generalmente el modelo se ajusta muy bien a las observaciones utilizadas como entrenamiento (conjunto de *train*). Como consecuencia, los 치rboles de decisi칩n tienden al *overfitting*. \n",
    "\n",
    "Para prevenirlo, utilizaremos dos hiperpar치metros:\n",
    "\n",
    "   - `max_depth`: la profundidad m치xima del 치rbol. Exploraremos los valores entre 4 y 10.\n",
    "   - `min_samples_split`: el n칰mero m칤nimo de observaciones que debe tener una hoja del 치rbol para poder dividir. Exploraremos los valores: 2, 10, 20, 50 y 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci칩n:</strong>\n",
    "\n",
    "Calculad el valor 칩ptimo de los hiperpar치metros `max_depth` y `min_samples_split`. Utilizad una b칰squeda de rejilla con validaci칩n cruzada para encontrar los valores 칩ptimos. Para cada combinaci칩n de valores, calcular su promedio y la desviaci칩n est치ndar. Haced un _heatmap_ para visualizar la precisi칩n seg칰n los diferentes valores de los hiperpar치metros.\n",
    "    \n",
    "P칩deis utilizar el m칩dulo `GridSearchCV` de `sklearn` el c치lculo de los mejores hiperpar치metros con el clasificador `DecisionTreeClassifier` (de `tree` de `sklearn`), y `heatmap` de `Seaborn`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Con el dataset de _train_, entrenad un 치rbol de desici칩n con la mejor combinaci칩n de par치metros encontrada.\n",
    "\n",
    "- Calculad el _accuracy_ del modelo obtenido sobre _train_ y _test_.\n",
    "\n",
    "- Calculad la matriz de confusi칩n sobre _test_.\n",
    "    \n",
    "- Representad gr치ficamente la frontera de decisi칩n con el de _test_.\n",
    "    \n",
    "- Representad el 치rbol. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - Comentar los resultados de la b칰squeda de los mejores hiperpar치metros.\n",
    "   - 쮺칩mo son las fronteras de decisi칩n? 쯊iene sentido que tengan esta forma con el algoritmo utilizado?\n",
    "   - 쮺칩mo son las predicciones obtenidas sobre el conjunto de test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ej2'></a>\n",
    "# 2. Implementaci칩n del caso pr치ctico (5 puntos)\n",
    "\n",
    "Como experto en an치lisis de datos, sabemos la importancia de que las empresas de tarjetas de cr칠dito puedan identificar y prevenir transacciones fraudulentas para proteger a sus clientes. En este sentido, estudiaremos un conjunto de datos que contiene informaci칩n sobre transacciones realizadas con tarjetas de cr칠dito en septiembre de 2013 por titulares de tarjetas europeos.\n",
    "\n",
    "Este conjunto de datos presenta transacciones ocurridas en dos d칤as, donde se registraron 492 casos de fraude de un total de 284,807 transacciones. Es importante destacar que todas las variables de entrada son num칠ricas y fueron obtenidas a trav칠s de una transformaci칩n PCA. Lamentablemente, debido a razones de confidencialidad, no se pueden proporcionar las caracter칤sticas originales ni m치s informaci칩n sobre los datos. Las variables V1 a V28 representan los componentes principales obtenidos con PCA, mientras que \"Time\" e \"Amount\" son las 칰nicas variables que no han sido transformadas con PCA. La variable \"Time\" indica los segundos transcurridos entre cada transacci칩n y la primera transacci칩n del conjunto de datos, mientras que \"Amount\" representa el monto de la transacci칩n. La variable \"Class\" es la variable de respuesta y toma el valor 1 en caso de fraude y 0 en caso contrario.\n",
    "\n",
    "Fuente: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. Carga de datos\n",
    "\n",
    "Lo primero que haremos ser치 cargar el conjunto de datos, visualizar las primeras filas, y verificar:\n",
    "\n",
    "- La cantidad total de filas y columnas en el DataFrame.\n",
    "- El nombre de cada columna del DataFrame.\n",
    "- El n칰mero de valores no nulos en cada columna.\n",
    "- El tipo de datos de cada columna, que puede ser int, float, object, entre otros.\n",
    "- La cantidad de memoria utilizada por el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Preprocesado de datos y an치lisis exploratorio\n",
    "\n",
    "El preprocesado y an치lisis exploratorio de los datos es un paso cr칤tico y fundamental en cualquier proyecto de an치lisis de datos o de aprendizaje autom치tico. Ayuda a los investigadores a comprender mejor los datos, descubrir patrones y relaciones, identificar problemas y seleccionar las t칠cnicas de an치lisis adecuadas para el conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong> \n",
    "\n",
    "Calculad las frecuencias de la variable _target_ (`Class`) y haced un gr치fico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong> \n",
    "\n",
    "Analizar la distribuci칩n de las variables descriptoras. Representa gr치ficamente el histograma de las 30 variables separ치ndo las observaciones seg칰n la clase a la que pertenece. Organiza todos los histogramas en 10 filas y 3 columnas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - 쮺칩mo es la relaci칩n de la frecuencias de la variable `Class`?\n",
    "   - 쯈u칠 informaci칩n nos proporcionan los histogramas?, 쮼xiste otra forma de visualizaci칩n que pudiera ser 칰til, en este caso?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "Los datos en bruto presentan algunos problemas. En primer lugar, las columnas `Time` y `Amount` son demasiado variables para utilizarlas directamente. Eliminad la columna `Time` (ya que no est치 claro qu칠 significa) y tomad el logaritmo de la columna `Amount` para reducir su rango.\n",
    "    \n",
    "Para evitar la indeterminaci칩n \"log(0)\", sum치dle 1 c칠ntimo de dolar (0.001) a la columna `Amount` antes de calcular el logaritmo. No olvid칠is que finalmente ten칠is que reemplazar la columna `Amount` por `Log Amount`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Separad los descriptores de la respuesta. Nombrad los conjuntos como: X, y.\n",
    "\n",
    "- Dividid el _dataset_ en dos subconjuntos, __*train*__ (80% de los datos) y __*test*__ (20% de los datos). Nombrad los conjuntos como: X_train, X_test, y_train, y_test. Pod칠is utlizar la funci칩n `train_test_split`de la biblioteca `model_selection`de `sklearn`. Utilizad la opci칩n `random_state = 24` y aseguraros que la divisi칩n sea estratificada, es decir, que se mantenga la misma proporci칩n de clases tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "Tened en cuenta que la matrices de las clases `y_train` e `y_test` deben estar codificadas. La funci칩n `to_categorical` de la librer칤a `TensorFlow` de `Keras` se utiliza para convertir una matriz de etiquetas de clase (enteros) en una matriz de etiquetas de clase codificadas en one-hot.\n",
    "\n",
    "La codificaci칩n one-hot es un proceso mediante el cual las etiquetas categ칩ricas se convierten en vectores binarios, donde cada vector tiene una longitud igual al n칰mero de clases. Cada vector tiene un valor de 1 en la posici칩n correspondiente a la clase y un valor de 0 en todas las dem치s posiciones. Esto se hace para permitir que los modelos de aprendizaje autom치tico comprendan mejor la estructura de las etiquetas categ칩ricas.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Normalizad los descriptores utilizando `StandardScaler`de `sklearn`. \n",
    "- Mostrad las dimensiones del conjunto de descriptores original, del conjunto de entrenamiento y del conjunto de prueba.\n",
    "    \n",
    "<strong>Nota:</strong> Recordad que el `StandardScaler` s칩lo se ajusta utilizando los descriptores de entrenamiento para evitar fugas de informaci칩n o \"data leakage\". La fuga de informaci칩n se produce cuando se utiliza informaci칩n de los datos de prueba o validaci칩n para ajustar el modelo. En otras palabras, si se ajusta el modelo de escalado con todo el conjunto de datos, se estar칤a utilizando informaci칩n de prueba o validaci칩n para el ajuste, lo que podr칤a hacer que el modelo parezca m치s preciso de lo que realmente es.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Entrenamiento, validaci칩n y prueba de una red neuronal con los datos originales\n",
    "\n",
    "Como herramienta de clasificaci칩n que nos permita predecir si una transacci칩n es fraudulenta o no, utilizaremos un perceptr칩n multicapa. Un perceptr칩n multicapa (MLP, por sus siglas en ingl칠s) es una red neuronal artificial compuesta por m칰ltiples capas de unidades de procesamiento (neuronas), donde cada capa est치 conectada a la siguiente capa a trav칠s de un conjunto de conexiones ponderadas. El MLP es capaz de realizar tanto tareas de clasificaci칩n como de regresi칩n al aprender a mapear las entradas a las salidas deseadas a trav칠s de una funci칩n de activaci칩n no lineal. La red utiliza un algoritmo de aprendizaje supervisado que ajusta los pesos de las conexiones durante el entrenamiento para minimizar la diferencia entre las salidas producidas por la red y las salidas deseadas. Debido a su capacidad para modelar relaciones no lineales complejas, el MLP es uno de los modelos m치s utilizados en el campo del aprendizaje autom치tico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos y entrenaremos una red Perceptr칩n Multicapa (MLP) con 4 capas ocultas de 20 neuronas cada una y con funci칩n de activaci칩n `relu`. Usaremos la clase `Sequential` de la libreria `keras`para crear el modelo de forma secuencial, es decir, apilando capas una encima de la otra. `Sequential` es la forma m치s sencilla de crear modelos de redes neuronales en `keras`, ya que no requiere definir la direcci칩n del grafo computacional como ocurre en otros tipos de modelos m치s complejos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Cread el modelo `Sequential`. Agregad las 4 capas ocultas con 20 neuronas cada una utilizando el m칠todo `.add()` y funci칩n de activaci칩n `relu`. Agregad la capa de salida con 2 neuronas de salida (una para la clase 0 y la otra para la clase 1) y funci칩n de activaci칩n `sigmoid`. Mostrad el resumen de la red creada con el m칠todo `.summary()`\n",
    "- Compilad el modelo utilizando el m칠todo `.compile()`, especificando el optimizador `adam`, la funci칩n de p칠rdida `binary_crossentropy` y las m칠trica de evaluaci칩n `accuracy`.\n",
    "- Entrenad el modelo utilizando el m칠todo `.fit()` con `X_train`, especificad el n칰mero de 칠pocas en 100 y el tama침o del lote en 2048. Validad su rendimiento haciendo validaci칩n cruzada con el 80% de los datos para el entrenamiento. Configura el par치metro `validation_split=0.2`.\n",
    "- Graficad la p칠rdida (`loss`) tanto de entrenamiento como de validaci칩n en funci칩n de las 칠pocas.\n",
    "- Graficad la exactitud (`accuracy`) tanto de entrenamiento como de validaci칩n en funci칩n de las 칠pocas.\n",
    "    \n",
    "<strong>Nota:</strong> Para la presentaci칩n del informe, configurad el par치metro `verbose=0`, para evitar mostrar informaci칩n durante el entreno.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado y validado el modelo, procederemos a hacer la prueba, es decir, predecir la clase de `X_test`y calcular las medidas de rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Predecid la clase de `X_test`, calculad la exacitud de la predicci칩n.\n",
    "- Calculad la matriz de confusi칩n\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - 쯈u칠 opinas de los resultados?, 쯡os podemos quedar con este modelo como aceptable?\n",
    "   - 쯃as medidas de rendimiento usadas son aceptables? 쯈ue otra medida de rendimiento propondr칤as?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Submuestreo\n",
    "\n",
    "El submuestreo se refiere a la t칠cnica de reducir el n칰mero de muestras de la clase mayoritaria para equilibrar la distribuci칩n de clases en un conjunto de datos.  Esto se puede lograr eliminando aleatoriamente muestras de la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Reduce el n칰mero de observaciones de la clase mayoritaria del conjunto de datos `X_train` hasta que tenga el mismo n칰mero de observaciones que la clase minoritaria. Muestra las dimensiones de las nuevas matrices de entrenamiento i la frecuencia de cada clase. Pod칠is utilizar la fuci칩n `resample` dela bibioteca `utils` de `sklearn`\n",
    "- Cread, entrenad, graficad las p칠rdidas y exactitud durante el entreno, validad y probad otro modelo `Sequential` con la misma configuraci칩n del apartado anterior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "- 쯇orqu칠 crees que se ha hecho un remuestreo solo a los datos de entrenamiento?\n",
    "- 쯈u칠 opinas de los resultados?, 쯡os podemos quedar con este modelo como aceptable?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Sobremuestreo\n",
    "\n",
    "Al contrario que el caso anterior, el sobremuestreo se refiere a la t칠cnica de aumentar el n칰mero de muestras de la clase minoritaria para equilibrar la distribuci칩n de clases en un conjunto de datos. Esto se puede lograr mediante la replicaci칩n de muestras existentes o mediante la generaci칩n de muestras sint칠ticas de las clases minoritarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Aumenta el n칰mero de observaciones de la clase minoritaria del conjunto de datos `X_train` hasta que tenga el mismo n칰mero de observaciones que la clase mayoritaria. Muestra las dimensiones de las nuevas matrices de entrenamiento i la frecuencia de cada clase. \n",
    "- Cread, entrenad, , graficad las p칠rdidas y exactitud durante el entreno, validad y probad otro modelo `Sequential` con la misma configuraci칩n del apartado anterior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - 쯇orqu칠 crees que se ha hecho un remuestreo solo a los datos de entrenamiento?\n",
    "   - 쯈u칠 opinas de los resultados?, 쯡os podemos quedar con este modelo como aceptable?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Generaci칩n de datos sint칠ticos\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) es una t칠cnica de sobremuestreo utilizada en el aprendizaje autom치tico para abordar el problema de clases desequilibradas. SMOTE se utiliza para aumentar el n칰mero de muestras de la clase minoritaria al generar nuevas muestras sint칠ticas.\n",
    "\n",
    "La t칠cnica SMOTE funciona de la siguiente manera: Para cada muestra en la clase minoritaria, SMOTE selecciona k vecinos cercanos y crea nuevas muestras en el espacio entre la muestra y sus vecinos. Estas nuevas muestras sint칠ticas son agregadas al conjunto de datos para aumentar el n칰mero de muestras de la clase minoritaria.\n",
    "\n",
    "La t칠cnica SMOTE se utiliza en combinaci칩n con otras t칠cnicas de preprocesamiento, como el submuestreo y la validaci칩n cruzada estratificada, para abordar el problema de clases desequilibradas en problemas de clasificaci칩n. Esta t칠cnica puede mejorar la capacidad del modelo para aprender patrones de las clases minoritarias y puede aumentar el rendimiento en la clasificaci칩n de clases minoritarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Mediante la t칠cnica SMOTE, aumenta el n칰mero de observaciones de la clase minoritaria de todo el conjunto de datos `X`. Puedes utilizar la funci칩n`SMOTE` de la librer칤a `over_sampling` de la bibioteca `imblearn` .  Muestra las dimensiones de las nuevas matrices de entrenamiento y la frecuencia de cada clase. \n",
    "- Cread, entrenad, graficad las p칠rdidas y exactitud durante el entreno, validad y probad otro modelo `Sequential` con la misma configuraci칩n del apartado anterior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An치lisis:</strong>\n",
    "\n",
    "   - 쯇orqu칠 crees que en este caso si se puede hacer el remuestreo a todo el conjunto de datos?\n",
    "   - 쯈u칠 opinas de los resultados?, 쮼ste es mejor que el anterior modelo? 쯡os podemos quedar con este modelo como aceptable?\n",
    "   - Enfoc치ndonos en las variables descriptoras, 쯖칩mo crees que se puede mejorar la predicci칩n?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Respuesta:</strong> \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Sintonizando los modelos (BONUS)\n",
    "\n",
    "Los modelos anteriores se han configurado con hiperpar치metros elegidos arbitrariamente y puede que no genere el modelo con el mejor rendimiento.  La b칰squeda de hiperpar치metros 칩ptimos es importante porque permite encontrar la combinaci칩n de par치metros que maximiza el rendimiento del modelo en los datos de prueba o validaci칩n, lo que a su vez proporciona un modelo m치s generalizable y preciso para nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci칩n:</strong>\n",
    "\n",
    "- Mediante la funci칩n `GridSearchCV` de `sklearn.model_selection` y la funci칩n `KerasClassifier` de `keras.wrappers.scikit_learn`, encuentra los hiperpar치metros 칩ptimos para los modelos con los conjunto de datos: submuestreado, sobremuestreado y con generaci칩n sint칠tica por medio de SMOTE. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci칩n:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
